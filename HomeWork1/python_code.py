# -*- coding: utf-8 -*-
"""Python_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OrU4_5yHWfKoS7iSWr4D091LGzKOXm4f
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = "/content/region_05.csv"
df = pd.read_csv(file_path)

# Display basic dataset information
def dataset_overview(df):
    print("Dataset Information:")
    print(df.info())
    print("\nFirst 5 Rows:")
    print(df.head())
    print("\nMissing Values:")
    print(df.isnull().sum())
    print("\nDuplicate Rows:", df.duplicated().sum())
    print("\nDescriptive Statistics:")
    print(df.describe())

dataset_overview(df)

# Handling Missing Values: Drop columns with more than 50% missing values
df_cleaned = df.dropna(thresh=len(df) * 0.5, axis=1)

# Filling remaining missing values with mode (for categorical) and median (for numerical)
for col in df_cleaned.columns:
    if df_cleaned[col].dtype == 'object':
        df_cleaned[col].fillna(df_cleaned[col].mode()[0], inplace=True)
    else:
        df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)

# Detecting and removing outliers using IQR method
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

numerical_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns
for col in numerical_cols:
    df_cleaned = remove_outliers(df_cleaned, col)

# Exploratory Data Analysis (EDA) Visualizations
plt.figure(figsize=(10, 6))
sns.histplot(df_cleaned['iyear'], bins=50, kde=True)
plt.title('Distribution of Events by Year')
plt.xlabel('Year')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x=df_cleaned['region'], y=df_cleaned['latitude'])
plt.title('Latitude Distribution by Region')
plt.xlabel('Region')
plt.ylabel('Latitude')
plt.show()

# Select only numeric columns for correlation analysis
numeric_df = df_cleaned.select_dtypes(include=['number'])

# Compute correlation matrix
corr_matrix = numeric_df.corr()

# Plot heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)
plt.title('Correlation Matrix')
plt.show()

# Save cleaned dataset for further analysis
df_cleaned.to_csv("/content/cleaned_region_05.csv", index=False)
print("Cleaned dataset saved.")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
file_path = "/content/region_05.csv"
df = pd.read_csv(file_path)

# Display basic info
print(df.info())
print(df.head())

# Check for missing values
missing_values = df.isnull().sum()
missing_values = missing_values[missing_values > 0].sort_values(ascending=False)

# Check for duplicate rows
duplicate_count = df.duplicated().sum()
print(f"Duplicate Rows: {duplicate_count}")

# Summary statistics for numerical columns
numerical_summary = df.describe()
print(numerical_summary)

# Remove duplicate rows
df_cleaned = df.drop_duplicates()

# Drop columns that are entirely empty
empty_cols = missing_values[missing_values == len(df)].index
df_cleaned = df_cleaned.drop(columns=empty_cols)

# Handle missing values in critical columns
df_cleaned = df_cleaned.dropna(subset=['iyear', 'country_txt', 'latitude', 'longitude'])

# Plot incidents per year
plt.figure(figsize=(12, 6))
sns.countplot(data=df_cleaned, x='iyear', palette="Blues", order=sorted(df_cleaned['iyear'].unique()))
plt.xticks(rotation=45)
plt.xlabel("Year")
plt.ylabel("Number of Incidents")
plt.title("Yearly Trend of Incidents")
plt.show()

# Top 10 countries with the most incidents
top_countries = df_cleaned['country_txt'].value_counts().head(10)

# Plot incidents by country
plt.figure(figsize=(12, 6))
sns.barplot(x=top_countries.index, y=top_countries.values, palette="Reds")
plt.xticks(rotation=45)
plt.xlabel("Country")
plt.ylabel("Number of Incidents")
plt.title("Top 10 Countries with the Most Incidents")
plt.show()

# Compute correlation matrix for numerical columns
corr_matrix = df_cleaned.select_dtypes(include=['float64', 'int64']).corr()

# Plot correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, cmap="coolwarm", annot=False, linewidths=0.5)
plt.title("Correlation Heatmap of Numerical Variables")
plt.show()

# Export cleaned dataset for Excel analysis
df_cleaned.to_csv("/content/cleaned_region_05.csv", index=False)
print("Cleaned dataset saved as 'cleaned_region_05.csv'.")